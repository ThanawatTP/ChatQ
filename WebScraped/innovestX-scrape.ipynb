{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.common.exceptions import NoSuchElementException, SessionNotCreatedException\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import time, json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content from <p>\n",
    "def get_content(driver,class_name):\n",
    "    section_elements = driver.find_elements(By.CLASS_NAME, class_name)\n",
    "    for div in section_elements:\n",
    "        p_tags = div.find_elements(By.TAG_NAME, 'p')\n",
    "        for p in p_tags:\n",
    "            yield p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <a> href attribute from <div>\n",
    "def get_links_btn(driver,class_name):\n",
    "    div_elements = []\n",
    "    for c in class_name:\n",
    "        div_elements += driver.find_elements(By.CLASS_NAME, c)\n",
    "    for div in div_elements:\n",
    "        a_tag = div.find_elements(By.TAG_NAME, 'a')\n",
    "        for a in a_tag:\n",
    "            yield a.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_last_page(driver,ul_class='pagination_page_number'):\n",
    "\n",
    "    while (True):\n",
    "        try:\n",
    "            # Find the 'Next' button element by its class\n",
    "            load_more_button = driver.find_element(By.XPATH, '//a[@aria-label=\"Go to next page\"]')\n",
    "            load_more_button.click()\n",
    "            print(\"Clicked 'Next Page' button\")\n",
    "            sleep(5)\n",
    "        except :\n",
    "            # No more button element\n",
    "            # get last number\n",
    "            ul = driver.find_element(By.CLASS_NAME, ul_class)\n",
    "            li_elements = ul.find_elements(By.TAG_NAME, 'li')\n",
    "            last_page = int(li_elements[-1].text.strip())\n",
    "            break\n",
    "\n",
    "    return last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get href each blogs from every pages number\n",
    "def get_links_blogs(link,last_page):\n",
    "    urls = []\n",
    "    for num_page in range(last_page):\n",
    "        page_url = f\"{link}/{num_page+1}\"\n",
    "        for l in get_links_btn(page_url,'blog_card_header'):\n",
    "            urls.append(l)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exist_class(driver,class_name):\n",
    "    for name in class_name:\n",
    "        try:\n",
    "            element = driver.find_element(By.CLASS_NAME, name)\n",
    "            if element:\n",
    "                yield name\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click footer button\n",
      "click footer button\n",
      "click footer button\n",
      "click footer button\n",
      "click footer button\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Safari()\n",
    "driver.get(\"https://www.innovestx.co.th\")\n",
    "\n",
    "urls = []\n",
    "h3_element = driver.find_elements(By.CSS_SELECTOR, 'h3.head')\n",
    "# Click footer button and collect href\n",
    "for h3 in h3_element:\n",
    "    try:\n",
    "        h3.click()\n",
    "        print('click footer button')\n",
    "        div_elements = driver.find_element(By.CLASS_NAME, 'footer_section_one')\n",
    "        a_tag = div_elements.find_elements(By.TAG_NAME, 'a')\n",
    "        for a in a_tag:\n",
    "            urls.append(a.get_attribute('href'))\n",
    "        sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start scraping\n",
    "urls = list(set(urls))\n",
    "visited_links = set()\n",
    "n = 0\n",
    "\n",
    "data = {\n",
    "        \"visited_links\" : list(visited_links),\n",
    "        \"urls\" : urls,\n",
    "        \"round\" : n\n",
    "    }\n",
    "\n",
    "# status_path = \"InnovestX/InnovestX_status.json\"\n",
    "\n",
    "# with open(status_path, \"w\") as json_file:\n",
    "#     json.dump(data, json_file, indent=4)\n",
    "    \n",
    "# df = pd.DataFrame({'content':[],'link':[]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_path = \"InnovestX/InnovestX_status.json\"\n",
    "href_class = ['blog_card_header','invest_guide ','swiper-wrapper','inner-plan-inverse', 'blog_list','container','pagination_page_number']\n",
    "\n",
    "with open(status_path, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    visited_links = set(data['visited_links'])\n",
    "    links = data['urls']\n",
    "    n = data['round']\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile_path = f'InnovestX/InnovestX_{n}records.csv'\n",
    "start_time = time.time()\n",
    "\n",
    "if os.path.exists(csvfile_path):\n",
    "    df = pd.read_csv(csvfile_path)\n",
    "else:\n",
    "    df = pd.DataFrame({'content':[],'link':[]})\n",
    "\n",
    "while links:\n",
    "    # get url then pop out\n",
    "    current_url = links.pop(0)\n",
    "    content = \" \"\n",
    "    \n",
    "    if current_url in visited_links or current_url[:27] != \"https://www.innovestx.co.th\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Current URL: {current_url}\")\n",
    "    \n",
    "    \n",
    "    # Cannot scrape pdf file\n",
    "    if current_url[:32] == \"https://www.innovestx.co.th/docs\":\n",
    "        new_record = [\"Document\", current_url]\n",
    "        df.loc[len(df.index)] = new_record\n",
    "        continue\n",
    "\n",
    "    n += 1\n",
    "    visited_links.add(current_url)\n",
    "\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get(current_url)\n",
    "\n",
    "    exist_class = list(check_exist_class(driver,href_class))\n",
    "    \n",
    "    # Block urls (has number label)\n",
    "    if \"pagination_page_number\" in exist_class:\n",
    "        try:\n",
    "            last_page = get_num_last_page(driver)\n",
    "            links += get_links_blogs(driver,last_page)\n",
    "            print(f\"Last pages: {last_page}\")\n",
    "        except :\n",
    "            pass\n",
    "    \n",
    "    # Block urls (has not number label)\n",
    "    try:\n",
    "        links += list(get_links_btn(driver,exist_class))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get content from <p>\n",
    "    if 'container' in exist_class:\n",
    "        content = \" \".join([text.strip() for text in get_content(driver,'container')])\n",
    "\n",
    "    links = list(set(links))\n",
    "    new_record = [content, current_url]\n",
    "    df.loc[len(df.index)] = new_record\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    print(f\"Remaining urls: {len(links)}\")\n",
    "    print(f\"Visited urls: {len(visited_links)}\\n\")\n",
    "\n",
    "    sleep(5)\n",
    "    \n",
    "    if not n%50:\n",
    "        data = {\n",
    "            \"visited_links\" : list(visited_links),\n",
    "            \"urls\" : links,\n",
    "            \"round\" : n,\n",
    "        }\n",
    "        with open(status_path, \"w\") as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "         \n",
    "        elapsed_time = time.time() - start_time\n",
    "        csvfile_path = f'InnovestX/InnovestX_{n}records.csv'\n",
    "        print(f'write file using {(elapsed_time/60):.2f} minutes')\n",
    "        df.to_csv(csvfile_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
