{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Database schema (.db) to soure of datatype format\n",
    "\n",
    "Datatype data format should look like this\n",
    "```json\n",
    "{\n",
    "  \"JOIN_KEY\": {\n",
    "    \"PK\": [\n",
    "      \"PK1\",\n",
    "      \"PK2\"\n",
    "    ],\n",
    "    \"FK\": {\n",
    "      \"FK1\": {\n",
    "        \"Ref_table\": \"Ref_column\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"COLUMNS\": {\n",
    "    \"Col1\": \"Type\",\n",
    "    \"Col2\": \"Type\",\n",
    "    \"Col3\": \"Type\"\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_schema(schema_db_path, output_path):\n",
    "\n",
    "    connection = sqlite3.connect(schema_db_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    for table in tables:\n",
    "        \n",
    "        schema = {\n",
    "                    \"JOIN_KEY\" : {\n",
    "                        \"PK\" : list(),\n",
    "                        \"FK\" : dict()\n",
    "                    },\n",
    "                    \"COLUMNS\" : dict()\n",
    "        }\n",
    "        table_name = table[0]\n",
    "        print(f\"Table: {table_name}\")\n",
    "        schema_file_name = f\"{table_name}_datatype.json\"\n",
    "        output_file_path = os.path.join(output_path, schema_file_name)\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        columns = cursor.fetchall()\n",
    "\n",
    "        for column in columns:\n",
    "            _, cname, ctype, _, _, pk_sq = column\n",
    "            schema['COLUMNS'][cname] = ctype\n",
    "\n",
    "            # if this column is primary key\n",
    "            if pk_sq: schema['JOIN_KEY']['PK'].append(cname)\n",
    "\n",
    "            print(f\"\\tColumn: {cname} {ctype} {pk_sq}\")\n",
    "\n",
    "            # Get foreign keys for the table\n",
    "        cursor.execute(f\"PRAGMA foreign_key_list({table_name});\")\n",
    "        foreign_keys = cursor.fetchall()\n",
    "        print()\n",
    "\n",
    "        if foreign_keys:\n",
    "            print(\"Foreign Keys:\")\n",
    "            for fk in foreign_keys:\n",
    "                _, _, to_table, fk_column, to_column, _, _, _ = fk\n",
    "                schema['JOIN_KEY']['FK'][fk_column] = {to_table : to_column}\n",
    "                print(f\"\\t{fk_column} REFERENCES {to_table}({to_column})\")\n",
    "            print()\n",
    "\n",
    "        with open(output_file_path, \"w\") as file:\n",
    "            json.dump(schema, file, indent=2)\n",
    "            print(f\"Dump {output_file_path} sucess\")\n",
    "            \n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded Domain schema type and description\n",
    "\n",
    "## JSON Structure Description\n",
    "\n",
    "The JSON embedded_data object has the following structure:\n",
    "```json\n",
    "{\n",
    "  \"name\": \"domain name\",\n",
    "  \"tables\": {\n",
    "    \"table_1\" : {\n",
    "      \"description\" : {\n",
    "        \"text\" : \"this is a description of table_1\",\n",
    "        \"vector\" : [Vector]\n",
    "      },\n",
    "      \"datatypes\" : {\n",
    "        \"JOIN_KEY\" : {\n",
    "          \"PK\" : [\"column_1\", \"column_3\"],\n",
    "          \"FK\" : {\n",
    "            \"column_3\" : \"table_2\"\n",
    "            }, \n",
    "          },\n",
    "        \"COLUMNS\" : {\n",
    "          \"column_1\" : \"number\",\n",
    "          \"column_2\" : \"text\",\n",
    "          \"column_3\" : \"text\"\n",
    "        }\n",
    "      },\n",
    "      \"class_labels\" : {\n",
    "        \"class_label_1\" : {\n",
    "          \"text\" : \"This is a class description for identify column type\",\n",
    "          \"vector\" : [Vector],\n",
    "        },\n",
    "        \"class_label_2\" : {\n",
    "          \"text\" : \"This is a class description for identify column type\",\n",
    "          \"vector\" : [Vector],\n",
    "        }\n",
    "      },\n",
    "      \"columns\" : {\n",
    "        \"column_1\" : {\n",
    "          \"text\" : \"This is a description of column_1\",\n",
    "          \"vector\" : [Vector],\n",
    "          \"column_classes\" : [\"class_label_1\"]\n",
    "        },\n",
    "        \"column_2\" : {\n",
    "          \"text\" : \"This is a description of column_2\",\n",
    "          \"vector\" : [Vector],\n",
    "          \"column_classes\" : [\"class_label_2\"]\n",
    "        },\n",
    "        \"column_3\" : {\n",
    "          \"text\" : \"This is a description of column_3\",\n",
    "          \"vector\" : [Vector],\n",
    "          \"column_classes\" : [\"class_label_1\", \"class_label_2\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"table_2\" : {...}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"models/nsql-350M\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"models/nsql-350M\")\n",
    "sen_emb = SentenceTransformer(\"models/all-MiniLM-L6-v2\")\n",
    "\n",
    "def encode(text):\n",
    "    return sen_emb.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_relate_topic(text:str, table_classes:dict,topic_threshold_score:float=0.4) -> list:\n",
    "    text_vec = encode(text)\n",
    "    topic_scores = [float(cos_sim(info['vector'], text_vec)) for info in table_classes.values()]\n",
    "    related_topic_indices = np.where(np.array(topic_scores) >= topic_threshold_score)[0]\n",
    "    \n",
    "    # If no topics meet the threshold, return the topic with maximum score\n",
    "    if not len(related_topic_indices) : \n",
    "        related_topic_indices = [np.argmax(topic_scores)]\n",
    "\n",
    "    related_topics = [list(table_classes.keys())[i] for i in related_topic_indices]\n",
    "    return related_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_embed_domain(domain_name, \n",
    "                     domain_description_folder_path,\n",
    "                     domain_datatype_folder_path,\n",
    "                     domain_schema_class_path):\n",
    "  \n",
    "  domain = {}\n",
    "  domain['name'] = domain_name\n",
    "  domain['tables'] = {}\n",
    "\n",
    "\n",
    "  with open(domain_schema_class_path, \"r\") as file:\n",
    "    schema_classes = json.load(file)\n",
    "\n",
    "  schema_classes_vector = dict()\n",
    "  for table_name, table_classes in schema_classes.items():\n",
    "    schema_classes_vector[table_name] = dict()\n",
    "    for class_label, class_description in table_classes.items():\n",
    "       schema_classes_vector[table_name][class_label] = { \"text\" : class_description,\n",
    "                                                          \"vector\" : encode(class_description) }\n",
    "\n",
    "  description_files = sorted(os.listdir(domain_description_folder_path))\n",
    "  datatype_files = sorted(os.listdir(domain_datatype_folder_path))\n",
    "  for description, datatype in zip(description_files, \n",
    "                                   datatype_files):\n",
    "\n",
    "    with open(os.path.join(domain_description_folder_path, description), 'r') as file:\n",
    "      description_body = json.load(file)\n",
    "    \n",
    "    with open(os.path.join(domain_datatype_folder_path, datatype), 'r') as file:\n",
    "      datatype_body = json.load(file)\n",
    "\n",
    "    # dev\n",
    "      \n",
    "    table_name = description_body['table']\n",
    "    column_classes = schema_classes_vector[table_name]\n",
    "    table_description = {}\n",
    "\n",
    "    table_description['text'] = description_body['description']\n",
    "    table_description['vector']= encode(description_body['description'])\n",
    "\n",
    "    columns = {}\n",
    "    for col, desc in description_body['columns'].items():\n",
    "      column = {}\n",
    "      column['text'] = desc\n",
    "      column['vector'] = encode(desc)\n",
    "      column['column_classes'] = most_relate_topic(desc, column_classes)\n",
    "      columns[col] = column\n",
    "\n",
    "    table = {}\n",
    "    table['description'] = table_description\n",
    "    table['datatypes'] = datatype_body\n",
    "    table['class_labels'] = column_classes\n",
    "    table['columns'] = columns\n",
    "\n",
    "    domain['tables'][table_name] = table\n",
    "\n",
    "  return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_name = 'coffee_shop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_description_folder_path = f'App/domain/{domain_name}/Schema/descriptions'\n",
    "domain_datatype_folder_path = f'App/domain/{domain_name}/Schema/datatypes'\n",
    "domain_schema_class_path = f'App/domain/{domain_name}/{domain_name}_classes.json'\n",
    "destination_path = 'src/test/embedded.json'\n",
    "\n",
    "with open(destination_path, 'w') as file:\n",
    "    json.dump(new_embed_domain(domain_name=domain_name,\n",
    "                               domain_description_folder_path=domain_description_folder_path,\n",
    "                               domain_datatype_folder_path=domain_datatype_folder_path,\n",
    "                               domain_schema_class_path=domain_schema_class_path), \n",
    "                            file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
