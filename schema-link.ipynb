{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, os, json\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"src/spider/database\"\n",
    "select_db = ['musical',\n",
    "             'farm', \n",
    "             'hospital_1', \n",
    "             'tvshow', \n",
    "             'cinema', \n",
    "             'restaurants', \n",
    "             'company_employee', \n",
    "             'company_1', \n",
    "             'company_offic', \n",
    "             'singer', \n",
    "             'coffee_shop']\n",
    "\n",
    "db = []\n",
    "\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        if file in select_db:\n",
    "            db_path = os.path.join(folder_path, file)\n",
    "            sqlite_db = [os.path.join(db_path, sql) for sql in os.listdir(db_path) if \".sqlite\" in sql]\n",
    "            db.append(*sqlite_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spider/database/musical/musical.sqlite',\n",
       " 'spider/database/farm/farm.sqlite',\n",
       " 'spider/database/hospital_1/hospital_1.sqlite',\n",
       " 'spider/database/tvshow/tvshow.sqlite',\n",
       " 'spider/database/cinema/cinema.sqlite',\n",
       " 'spider/database/restaurants/restaurants.sqlite',\n",
       " 'spider/database/company_employee/company_employee.sqlite',\n",
       " 'spider/database/company_1/company_1.sqlite',\n",
       " 'spider/database/coffee_shop/coffee_shop.sqlite',\n",
       " 'spider/database/singer/singer.sqlite']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(sqlite_db):\n",
    "    connection = sqlite3.connect(sqlite_db)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        print(f\"Table: {table_name}\")\n",
    "\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        columns = cursor.fetchall()\n",
    "\n",
    "        for column in columns:\n",
    "            column_name = column[1]\n",
    "            print(f\"  Column: {column_name}\")\n",
    "\n",
    "        print()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for table in db:\n",
    "#     get_schema(table)\n",
    "#     print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"src\"\n",
    "schema_description_file = \"mockup_schema_description.json\"\n",
    "with open(os.path.join(src_folder, schema_description_file)) as f:\n",
    "    dbs = json.load(f)\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description_emb = []\n",
    "\n",
    "# for db in dbs:\n",
    "#     schema_emb = {}\n",
    "#     table_name = db['table']\n",
    "#     table_description = db['description']\n",
    "#     schema_emb[table_name] = model.encode(table_description).tolist()\n",
    "#     columns = list(db['columns'].keys())\n",
    "#     for col in columns:\n",
    "#         column_description = db['columns'][col]\n",
    "#         schema_emb[col] = model.encode(column_description).tolist()\n",
    "#     description_emb.append(schema_emb)\n",
    "\n",
    "# schema_vector_file = \"mockup_schema_description_vector.json\"\n",
    "# with open(os.path.join(src_folder, schema_vector_file), \"w\") as f:\n",
    "#     json.dump(description_emb,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_vector_file = \"mockup_schema_description_vector.json\"\n",
    "with open(os.path.join(src_folder, schema_vector_file)) as f:\n",
    "    schema_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_table : filter by table before \n",
    "def filter_tables(question, column_threshold = 0.4, table_threshold = 0.2, filter_tables = True):\n",
    "    question_emb = model.encode(question)\n",
    "    used_schema = {}\n",
    "    for i in range(len(schema_vector)):\n",
    "        table_name = list(schema_vector[i].keys())[0]\n",
    "\n",
    "        table_description_vector = schema_vector[i][table_name]\n",
    "        if filter_tables and util.cos_sim(table_description_vector, question_emb) < table_threshold: continue\n",
    "        \n",
    "        used_col = []\n",
    "        for col, vec in schema_vector[i].items():\n",
    "            if col == table_name: continue\n",
    "            score = float(util.cos_sim(vec, question_emb))\n",
    "            if score > column_threshold:\n",
    "                column_description = [dbs[i]['columns'][col] for i in range(len(dbs)) if dbs[i]['table'] == table_name][0]\n",
    "                print(f\"{table_name} - {col} : {score:.2f}\\nDescription : {column_description}\\n\")\n",
    "                used_col.append(col)\n",
    "        if len(used_col) > 0: used_schema[table_name] = used_col\n",
    "    return used_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Count singers who born at French\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people - Nationality : 0.35\n",
      "Description : Nationality of the person\n",
      "\n",
      "singer - Singer_ID : 0.39\n",
      "Description : Unique identifier for the singer\n",
      "\n",
      "singer - Name : 0.45\n",
      "Description : Name of the singer\n",
      "\n",
      "singer - Birth_Year : 0.54\n",
      "Description : Year of birth of the singer\n",
      "\n",
      "singer - Net_Worth_Millions : 0.39\n",
      "Description : Net worth of the singer in millions\n",
      "\n",
      "singer - Citizenship : 0.45\n",
      "Description : Citizenship of the singer\n",
      "\n",
      "song - Singer_ID : 0.42\n",
      "Description : Identifier of the singer who performed the song\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'people': ['Nationality'],\n",
       " 'singer': ['Singer_ID',\n",
       "  'Name',\n",
       "  'Birth_Year',\n",
       "  'Net_Worth_Millions',\n",
       "  'Citizenship'],\n",
       " 'song': ['Singer_ID']}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_tables(question, column_threshold = 0.3, filter_tables = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2026, 2171, 2003, 2084, 10830, 2102, 102]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer('hello my name is Thanawat')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"SCB TechX, an SCBX company specializing in digital technology, has introduced PointX, the latest platform development. \n",
    "It is a new world that lets reward point collectors experience unlimited reward point accumulation and redemption. \n",
    "With a concept of all-in-one reward point wallet platform, customers can use reward points like cash for purchases at any shops displaying the PointX logo, \n",
    "get discount coupons for shopping for flash deals and special priced items via an in-app X Store, transfer and share reward points, \n",
    "and enjoy using reward points at bonus rates every day. The PointX application is starting pilot services for Siam Commercial Bank (SCB) credit cardholders with reward point programs before rolling out to SCBâ€™s other customer segments and other business partners in the future.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForPreTraining\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"models/electra-large-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sc', '##b', 'tech', '##x', ',', 'an', 'sc', '##b', '##x', 'company']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(test_text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_of_column(column):\n",
    "    db = []\n",
    "    for i in range(len(schema_vector)):\n",
    "        schema = {}\n",
    "        table_name = dbs[i]['table']\n",
    "        columns_name = list(dbs[i]['columns'].keys())\n",
    "        schema[table_name] = columns_name\n",
    "        db.append(schema)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string mathing , max_score = weight of string match\n",
    "def column_from_question(question, default_score=0.6):\n",
    "    used_table_col = {}\n",
    "    # question_tokens = [token.lower() for token in tokenizer.tokenize(question)]\n",
    "    question_tokens = [token.lower() for token in question.split()]\n",
    "    print(question_tokens)\n",
    "    for table in schema_vector:\n",
    "        max_score = default_score\n",
    "        for token in question_tokens:\n",
    "            cols = [ key.lower() for key in table.keys()]\n",
    "            table_name = cols.pop(0)\n",
    "            if token == table_name: \n",
    "                max_score = 1.0\n",
    "                if used_table_col.get(token): used_table_col = {key: max_score for key in used_table_col[token]}\n",
    "            if token in cols: \n",
    "                used_table_col.setdefault(table_name, {}).update({token : max_score})\n",
    "\n",
    "    return used_table_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'many', 'singer', 'have', 'singer_id']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'singer': {'singer_id': 1.0}, 'song': {'singer_id': 0.6}}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_from_question(\"How many singer have singer_id \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Musical_ID', 'Name', 'Year', 'Award', 'Category', 'Nominee', 'Result']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dbs[0]['columns'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['musical', 'Musical_ID', 'Name', 'Year', 'Award', 'Category', 'Nominee', 'Result']\n"
     ]
    }
   ],
   "source": [
    "cols = list(schema_vector[0].keys())\n",
    "print(cols)\n",
    "t = cols.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Musical_ID', 'Name', 'Year', 'Award', 'Category', 'Nominee', 'Result']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_key': ['ab']}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'new_key': ['ab']}  # Create an empty dictionary\n",
    "key = 'new_key'\n",
    "\n",
    "my_dict.setdefault(key, [])  # Update the dictionary with the key-value pair\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
