{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import re, gensim\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "  for sentence in sentences:\n",
    "    sentence = re.sub(r'https?://\\S+|www\\.\\S+', '', sentence)\n",
    "    sentence = ''.join([char for char in sentence if char.isascii()])\n",
    "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "  \n",
    "def list_of_sentence(text):\n",
    "    sentences = sent_tokenize(text.lower())\n",
    "    los = list(sent_to_words(sentences))\n",
    "    return los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_of_lists_to_text(file_path, data, delimiter='\\t'):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for sublist in data:\n",
    "            line = delimiter.join(sublist)\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "def import_text_to_list_of_lists(file_path, delimiter='\\t'):\n",
    "    result = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace and newlines\n",
    "            sublist = line.split(delimiter)\n",
    "            result.append(sublist)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_contents(link, div_class = 'elementor-widget-container'):\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get(link)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_=div_class)\n",
    "\n",
    "    paragraphs = []\n",
    "    for div in div_elements:\n",
    "        div_paragraphs = div.find_all('p')\n",
    "        for paragraph in div_paragraphs:\n",
    "            paragraphs.append(paragraph.text.replace('\\xa0', ''))\n",
    "\n",
    "    driver.quit()\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, target_language):\n",
    "    translator = Translator()\n",
    "    detected_lang = \"th\"\n",
    "    translated_text = translator.translate(text, src=detected_lang, dest=target_language)\n",
    "    return translated_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Service & Product Page\n",
    "\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://scbtechx.io/services-products/')\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "sp_h2_content = soup.find_all('h2', class_='elementor-heading-title elementor-size-default')\n",
    "sp_content = [text.text for text in sp_h2_content]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Terms-of-use Page\n",
    "\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://scbtechx.io/terms-of-use/')\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "span_elements = soup.find_all('span', style='font-weight: 400;')\n",
    "tou_content = [span.text.replace('\\xa0', '') for span in span_elements]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n"
     ]
    }
   ],
   "source": [
    "#Scraping links on news page with click load more button\n",
    "\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://scbtechx.io/news/')\n",
    "wait_duration = 5\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Find the button element by its class\n",
    "        load_more_button = driver.find_element(By.CLASS_NAME, \"wpr-load-more-btn\")\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", load_more_button)\n",
    "        load_more_button.click()\n",
    "        print(\"Clicked 'Load More' button\")\n",
    "        sleep(wait_duration)\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        break\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "section = soup.find(\"section\", class_=\"wpr-grid elementor-clearfix grid-images-loaded\")\n",
    "a_tags = section.find_all(\"a\")\n",
    "\n",
    "keep_links = [link.get('href') for link in a_tags]\n",
    "news_lisks = [link for link in set(keep_links) if link.startswith('https://scbtechx.io/') and 'https://scbtechx.io/category/' not in link]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [26:33<00:00, 23.09s/it]   \n"
     ]
    }
   ],
   "source": [
    "links = ['https://scbtechx.io/privacy-notice/customers/',\n",
    "         'https://scbtechx.io/privacy-notice/non-customers/',\n",
    "         'https://scbtechx.io/data-platform/',\n",
    "         'https://scbtechx.io/ekyc/',\n",
    "         'https://scbtechx.io/ekyc-innovestx/']\n",
    "\n",
    "links += news_lisks\n",
    "\n",
    "pages_cons = []\n",
    "\n",
    "for link in tqdm(links):\n",
    "    \n",
    "    pages_cons.append(page_contents(link))\n",
    "    sleep(10)\n",
    "\n",
    "all_contents = pages_cons + [tou_content] + [sp_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corpus = [list_of_sentence(\" \".join(c)) for c in all_contents]\n",
    "los_all_corpus = [list_of_sentence for corpus in all_corpus for list_of_sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'src/TechX_corpus.txt'\n",
    "write_list_of_lists_to_text(file_path, los_all_corpus, delimiter='\\t')\n",
    "# techx_los = import_text_to_list_of_lists(file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check word freq\n",
    "# from collections import defaultdict\n",
    "\n",
    "# word_freq = defaultdict(int)\n",
    "# for sublist in techx_los:\n",
    "#     for word in sublist:\n",
    "#         word_freq[word] += 1\n",
    "# word_freq = dict(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PointX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scping links on promotion page\n",
    "\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://www.pointx.scb/promotions/')\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "\n",
    "div = soup.find(\"div\", class_=\"special-promotion-carousel-container carousel-share\")\n",
    "a_tags = div.find_all(\"a\")\n",
    "\n",
    "links = [a.get(\"href\") for a in a_tags]\n",
    "links = list(set(links))    # drop duplicate\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointx_page_contents(link):\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get(link)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    p_tags = soup.find_all(\"p\")\n",
    "    p_texts = [re.sub(r\"[\\n\\t]\",\" \",tag.text )for tag in p_tags if tag.text.strip()]\n",
    "    \n",
    "    li_tags = soup.find_all(\"li\")\n",
    "    li_texts = [re.sub(r\"[\\n\\t]\",\" \",tag.text ) for tag in li_tags if tag.text.strip()]\n",
    "\n",
    "    driver.quit()\n",
    "    return p_texts + li_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:21<00:00, 13.57s/it]\n"
     ]
    }
   ],
   "source": [
    "pages_cons = []\n",
    "\n",
    "for link in tqdm(links):\n",
    "    pages_cons.append(pointx_page_contents(link))\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:33<00:00, 15.53s/it]\n"
     ]
    }
   ],
   "source": [
    "all_corpus = []\n",
    "for content in tqdm(pages_cons):\n",
    "    los_en = [translate_text(sentence,'en') for sentence in content]\n",
    "    all_corpus.append(list_of_sentence(\" \".join(los_en)))\n",
    "\n",
    "los_all_corpus = [list_of_sentence for corpus in all_corpus for list_of_sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'src/PointX_corpus.txt'\n",
    "write_list_of_lists_to_text(file_path, los_all_corpus, delimiter='\\t')\n",
    "# pointx_los = import_text_to_list_of_lists(file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = \"Tips for You\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n",
      "Clicked 'Load More' button\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Safari()\n",
    "driver.get('https://www.scb.co.th/en/personal-banking/stories.html')\n",
    "\n",
    "wait_duration = 5\n",
    "rounds = True\n",
    "tip4u_Title_button = driver.find_element(By.XPATH, f'//a[@class=\"ga_menu_section\" and @title=\"{Title}\"]')\n",
    "tip4u_Title_button.click()\n",
    "\n",
    "while (rounds):\n",
    "    try:\n",
    "        # Find the button element by its class\n",
    "        load_more_button = driver.find_element(By.XPATH, '//a[@class=\"btn-default mar-top ga_see_all_button\" and @title=\"Load more\"]')\n",
    "        # driver.execute_script(\"arguments[0].scrollIntoView();\", load_more_button)\n",
    "        load_more_button.click()\n",
    "        print(\"Clicked 'Load More' button\")\n",
    "        sleep(wait_duration)\n",
    "        # rounds -= 1\n",
    "    except :\n",
    "        break\n",
    "\n",
    "div_element = driver.find_element(By.CSS_SELECTOR, \"div.row.relative.clearfix\")\n",
    "\n",
    "link_elements = div_element.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "links = [link.get_attribute(\"href\") for link in link_elements]\n",
    "links = list(set(links))    # drop duplicate\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [17:47<00:00, 14.62s/it]\n"
     ]
    }
   ],
   "source": [
    "pages_cons = []\n",
    "for link in tqdm(links):\n",
    "    pages_cons.append(page_contents(link,div_class=\"content\"))\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corpus = []\n",
    "for c in pages_cons:\n",
    "    all_corpus.append(list_of_sentence(\" \".join(c)))\n",
    "    \n",
    "los_all_corpus = [list_of_sentence for corpus in all_corpus for list_of_sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'src/SCB_corpus.txt'\n",
    "write_list_of_lists_to_text(file_path, los_all_corpus, delimiter='\\t')\n",
    "# scb_tip4u_los = import_text_to_list_of_lists(file_path, delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
