{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, json, warnings\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_350M = AutoTokenizer.from_pretrained(\"../models/nsql-350M\")\n",
    "model_350M = AutoModelForCausalLM.from_pretrained(\"../models/nsql-350M\")\n",
    "\n",
    "# tokenizer_2B = AutoTokenizer.from_pretrained(\"../models/nsql-2B\")\n",
    "# model_2B = AutoModelForCausalLM.from_pretrained(\"../models/nsql-2B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/spider/table_database_map.json\") as f:\n",
    "    table_map_db = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/NSText2SQL/train_spider.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_column_of_create_table(query):\n",
    "    lines = query.splitlines()\n",
    "    columns = []\n",
    "    table_names = []\n",
    "\n",
    "    # Look for \"CREATE TABLE\" and start capturing columns\n",
    "    capture = False\n",
    "    for line in lines:\n",
    "        if \"CREATE TABLE\" in line:\n",
    "            capture = True\n",
    "            table_names.append(line.split()[-2].lower())\n",
    "        elif line.strip().endswith(')') or line.strip().endswith(');'):\n",
    "            capture = False\n",
    "        elif capture:\n",
    "            column_name = line.strip().split()[0]\n",
    "            if column_name in [\"CONSTRAINT\", \"PRIMARY\"]: continue\n",
    "            columns.append(column_name)\n",
    "    return table_names, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, schema):\n",
    "    full_prompt = \"\"\n",
    "    full_prompt += f\"{str(schema)}\\n\\n\"\n",
    "    full_prompt += \"-- Using valid SQLite, answer the following questions for the tables provided above.\\n\\n\"\n",
    "    full_prompt += f\"--{question}\\n\\nSELECT\"\n",
    "    return full_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_sql(prompt, model_name):\n",
    "\n",
    "    if model_name == \"nsql-350M\":\n",
    "        input_ids = tokenizer_350M(prompt, return_tensors=\"pt\").input_ids\n",
    "        generated_ids = model_350M.generate(input_ids, max_length=500)\n",
    "        return tokenizer_350M.decode(generated_ids[0], skip_special_tokens=True).split('\\n')[-1]\n",
    "    # elif model_name == \"nsql-2B\":\n",
    "    #     input_ids = tokenizer_2B(prompt, return_tensors=\"pt\").input_ids\n",
    "    #     generated_ids = model_2B.generate(input_ids, max_length=500)\n",
    "    #     return tokenizer_2B.decode(generated_ids[0], skip_special_tokens=True).split('\\n')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(sql_query, db_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(f'../src/spider/database/{db_name}/{db_name}.sqlite')\n",
    "        cursor = conn.cursor()\n",
    "    except:\n",
    "        return \"CANNOT CONNECT DATABASE\"\n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        results = cursor.fetchall()\n",
    "    except:\n",
    "        return \"CANNOT FETCHING DATA\"\n",
    "    conn.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_query_results = []\n",
    "nsql350M_query_results = []\n",
    "nsql350M_query = []\n",
    "nsql2B_query_results = []\n",
    "nsql2B_query = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i, row in df.iterrows():\n",
    "        question = row['Question']\n",
    "        print(question)\n",
    "        schema = row['Table']\n",
    "        expect_query = row['SQL']\n",
    "        schema_tables = table_column_of_create_table(schema)[0]\n",
    "        try:\n",
    "            db_of_table = table_map_db[schema_tables[0].lower()]\n",
    "        except KeyError:\n",
    "            error_occur = \"TABLE NOT MATCH\"\n",
    "            expect_query_results.append(error_occur)\n",
    "            nsql350M_query.append(error_occur)\n",
    "            nsql350M_query_results.append(error_occur)\n",
    "            # nsql2B_query.append(error_occur)\n",
    "            # nsql2B_query_results.append(error_occur)\n",
    "            continue\n",
    "\n",
    "        expect_result = query_db(expect_query, db_of_table)\n",
    "        full_prompt = create_prompt(question, schema)\n",
    "        # try:\n",
    "        #     pred_sql_query_350M = pred_sql(full_prompt, \"nsql-350M\")\n",
    "        # except:\n",
    "        #     pred_sql_query_350M = \"GEN QUERY ERROR\"\n",
    "        pred_sql_query_350M = \"test\"\n",
    "        print(pred_sql_query_350M)\n",
    "        pred_result_350M = query_db(pred_sql_query_350M, db_of_table)\n",
    "        \n",
    "        # try:\n",
    "        #     pred_sql_query_2B = pred_sql(full_prompt, \"nsql-2B\")\n",
    "        # except:\n",
    "        #     pred_sql_query_2B = \"GEN QUERY ERROR\"\n",
    "        # print(pred_sql_query_2B)\n",
    "        # pred_result_2B = query_db(pred_sql_query_2B, db_of_table)\n",
    "\n",
    "        expect_query_results.append(expect_result)\n",
    "        nsql350M_query.append(pred_sql_query_350M)\n",
    "        nsql350M_query_results.append(pred_result_350M)\n",
    "        # nsql2B_query.append(pred_sql_query_2B)\n",
    "        # nsql2B_query_results.append(pred_result_2B)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nsql-350M-query'] = nsql350M_query\n",
    "# df['nsql-2B-query'] = nsql2B_query\n",
    "df['expect_result'] = expect_query_results\n",
    "df['nsql-350M-result'] = nsql350M_query_results\n",
    "# df['nsql-2B-result'] = nsql2B_query_results\n",
    "\n",
    "df.to_csv(\"model-expirements.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../src/temp-model-expirements.csv\")\n",
    "exclude_values = [\"CANNOT FETCHING DATA\", \"TABLE NOT MATCH\", None]\n",
    "filtered_df = df[~df['Expect-result'].isin(exclude_values)]\n",
    "print(filtered_df.shape)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(\"model-exp.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
